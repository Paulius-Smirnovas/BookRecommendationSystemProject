{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c70ec70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m---> 11\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[43m__name\u001b[49m)\n\u001b[0;32m     13\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpauli\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbooksummaries.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m,  encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mNameError\u001b[0m: name '__name' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from flask import Flask, render_template, request\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "data = []\n",
    "with open(r\"C:\\Users\\pauli\\Desktop\\booksummaries.txt\", \"r\",  encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, dialect='excel-tab')\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "\n",
    "# convert data to pandas dataframe\n",
    "books = pd.DataFrame.from_records(data, columns=['book_id', 'freebase_id', 'book_title', 'author', 'publication_date', 'genre', 'summary'])\n",
    "books.head()\n",
    "def parse_genre_entry(genre_info):\n",
    "    if genre_info == '':\n",
    "        return []\n",
    "    genre_dict = json.loads(genre_info)\n",
    "    genres = list(genre_dict.values())\n",
    "    return genres\n",
    "\n",
    "books['genre'] = books['genre'].apply(parse_genre_entry)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "books['summary'] = books['summary'].fillna('')\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(books['summary'])\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_similarity = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "# sklearn TF-IDF defaults to using L2 Norm, for which linear kernel == cosine similarity\n",
    "\n",
    "def clean_flatten(data):\n",
    "    cleaned = []\n",
    "    for entry in data:\n",
    "        # strip spaces and flatten into small caps\n",
    "        cleaned.append(str.lower(entry.replace(' ', '')))\n",
    "    return cleaned\n",
    "\n",
    "books['genre_kws'] = books['genre'].apply(clean_flatten)\n",
    "books['author_kws'] = books['author'].apply(lambda x: str.lower(x.replace(' ', '')))\n",
    "\n",
    "def merge_kws(df):\n",
    "    return ' '.join(df.genre_kws) + ' ' + df.author_kws\n",
    "\n",
    "books['kws'] = books.apply(merge_kws, axis=1)\n",
    "\n",
    "indices = pd.Series(books.index, index=books['book_title']).drop_duplicates()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books['kws'])\n",
    "kw_similarity = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "def recommend(titles, similarity_matrix, topk=10):\n",
    "    book_indices = [indices[title] for title in titles]\n",
    "    \n",
    "    # Initialize combined_vector as an array of zeros with appropriate length\n",
    "    combined_vector = np.zeros(similarity_matrix.shape[1])\n",
    "    \n",
    "    # Add up the vectors for each title\n",
    "    for index in book_indices:\n",
    "        sim_vector = similarity_matrix[index]\n",
    "        print(f\"Shape of sim_vector: {sim_vector.shape}\")  # Print shape for debugging\n",
    "        \n",
    "        if sim_vector.shape != combined_vector.shape:\n",
    "            print(f\"Skipping index {index} due to shape mismatch\")\n",
    "            continue  # Skip this iteration if shapes do not match\n",
    "        \n",
    "        combined_vector += sim_vector\n",
    "        \n",
    "    combined_vector /= len(book_indices)  # Normalize by the number of titles\n",
    "\n",
    "    similarity_scores = list(enumerate(combined_vector))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_scores = similarity_scores[:topk]  # Get top k scores\n",
    "    \n",
    "    recommendation_indices = [i[0] for i in top_scores]\n",
    "\n",
    "    return books['book_title'].iloc[recommendation_indices]\n",
    "\n",
    "titles_to_recommend = ['The Stranger']\n",
    "recs = recommend(titles_to_recommend, kw_similarity)\n",
    "# print(recs)\n",
    "books.iloc[recs.index]\n",
    "\n",
    "\n",
    "# Your book recommendation code here\n",
    "\n",
    "# Define the route for the home page\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# Define the route for the recommendation results page\n",
    "@app.route('/recommend', methods=['POST'])\n",
    "def recommend():\n",
    "    title = request.form.get('book_title')\n",
    "    titles_to_recommend = [title]\n",
    "    recs = recommend(titles_to_recommend, cosine_similarity)\n",
    "    recommended_books = books.iloc[recs.index]\n",
    "\n",
    "    return render_template('recommendation.html', books=recommended_books)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ae498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
